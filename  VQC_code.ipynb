{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPdDlE-lMw8F",
        "outputId": "22dbb8d3-2cca-4446-a717-0836f4fa0b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit==0.7.2\n",
            "  Downloading qiskit-0.7.2.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qiskit-terra<0.8,>=0.7 (from qiskit==0.7.2)\n",
            "  Downloading qiskit-terra-0.7.2.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qiskit-aer<0.2,>=0.1 (from qiskit==0.7.2)\n",
            "  Downloading qiskit-aer-0.1.0.tar.gz (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.0/223.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer<0.2,>=0.1->qiskit==0.7.2) (1.26.4)\n",
            "Collecting jsonschema<2.7,>=2.6 (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2)\n",
            "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting marshmallow<3,>=2.16.3 (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2)\n",
            "  Downloading marshmallow-2.21.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting marshmallow_polyfield<4,>=3.2 (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2)\n",
            "  Downloading marshmallow_polyfield-3.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (3.3)\n",
            "Requirement already satisfied: pillow>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (9.4.0)\n",
            "Collecting ply>=3.10 (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (2.32.3)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: scipy!=0.19.1,>=0.19 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (1.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (2024.8.30)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm>=1.1.0->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (43.0.0)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-terra<0.8,>=0.7->qiskit==0.7.2)\n",
            "  Downloading pyspnego-0.11.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-terra<0.8,>=0.7->qiskit==0.7.2) (2.22)\n",
            "Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Downloading marshmallow-2.21.0-py2.py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow_polyfield-3.2-py3-none-any.whl (17 kB)\n",
            "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading pyspnego-0.11.1-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: qiskit, qiskit-aer, qiskit-terra\n",
            "\u001b[33m  WARNING: Legacy build of wheel for 'qiskit' created no files.\n",
            "  Command arguments: /usr/bin/python3 -u -c '\n",
            "  exec(compile('\"'\"''\"'\"''\"'\"'\n",
            "  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\n",
            "  #\n",
            "  # - It imports setuptools before invoking setup.py, to enable projects that directly\n",
            "  #   import from `distutils.core` to work with newer packaging standards.\n",
            "  # - It provides a clear error message when setuptools is not installed.\n",
            "  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\n",
            "  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\n",
            "  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\n",
            "  # - It generates a shim setup.py, for handling setup.cfg-only projects.\n",
            "  import os, sys, tokenize\n",
            "  \n",
            "  try:\n",
            "      import setuptools\n",
            "  except ImportError as error:\n",
            "      print(\n",
            "          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\n",
            "          \"the build environment.\",\n",
            "          file=sys.stderr,\n",
            "      )\n",
            "      sys.exit(1)\n",
            "  \n",
            "  __file__ = %r\n",
            "  sys.argv[0] = __file__\n",
            "  \n",
            "  if os.path.exists(__file__):\n",
            "      filename = __file__\n",
            "      with tokenize.open(__file__) as f:\n",
            "          setup_py_code = f.read()\n",
            "  else:\n",
            "      filename = \"<auto-generated setuptools caller>\"\n",
            "      setup_py_code = \"from setuptools import setup; setup()\"\n",
            "  \n",
            "  exec(compile(setup_py_code, filename, \"exec\"))\n",
            "  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/tmp/pip-install-kkwzote2/qiskit_e2da8e8b02254fff965633297fc8b8e4/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' bdist_wheel -d /tmp/pip-wheel-qiitoxpz\n",
            "  Command output:\n",
            "  running bdist_wheel\n",
            "\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Running setup.py clean for qiskit\n",
            "  Building wheel for qiskit-aer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit-aer: filename=qiskit_aer-0.1.0-py3-none-any.whl size=1285 sha256=4b655764dc90c8a0d1f24560f78f883515db1aa20263abe7b768c8cea7c26187\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/96/28/f99aede11517f2e46cea9e5473d487e66582038f9696b228ea\n",
            "  Building wheel for qiskit-terra (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit-terra: filename=qiskit_terra-0.7.2-cp310-cp310-linux_x86_64.whl size=744236 sha256=389906b1ed1105efa95b5757c0c2643b407e1f6eff45aee35dd6e058109c4328\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/cd/06/cd4022b3af93c8c342e0468a4a75fd342c068a6c7926285458\n",
            "Successfully built qiskit-aer qiskit-terra\n",
            "Failed to build qiskit\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (qiskit)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=9dbaba6b997533888dc4b18a4706e05d1015b0c435c614a08bf2d80e9c74336c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc\n",
            "Successfully installed pylatexenc-2.10\n",
            "Collecting qiskit-machine-learning\n",
            "  Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting qiskit>=0.44 (from qiskit-machine-learning)\n",
            "  Downloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit-algorithms>=0.2.0 (from qiskit-machine-learning)\n",
            "  Downloading qiskit_algorithms-0.3.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (1.3.2)\n",
            "Collecting fastdtw (from qiskit-machine-learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (71.0.4)\n",
            "Collecting dill>=0.3.4 (from qiskit-machine-learning)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit-machine-learning) (1.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit-machine-learning) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit-machine-learning) (4.12.2)\n",
            "Collecting symengine>=0.11 (from qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit-machine-learning) (1.16.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit-machine-learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_algorithms-0.3.0-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.6/308.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (39.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=512548 sha256=f4a73962faf912784c6c38e6ab4e4317edc9a01060cbf6b1782b59c838a7b70e\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: symengine, rustworkx, pbr, fastdtw, dill, stevedore, qiskit, qiskit-algorithms, qiskit-machine-learning\n",
            "Successfully installed dill-0.3.8 fastdtw-0.3.4 pbr-6.1.0 qiskit-1.2.0 qiskit-algorithms-0.3.0 qiskit-machine-learning-0.7.2 rustworkx-0.15.1 stevedore-5.3.0 symengine-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit==0.7.2\n",
        "!pip install pylatexenc\n",
        "!pip install qiskit-machine-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCQfG_ajMw8J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from qiskit.circuit.library import PauliFeatureMap, EfficientSU2,RealAmplitudes,ZZFeatureMap\n",
        "from qiskit_algorithms.optimizers import SPSA,COBYLA, ADAM\n",
        "from qiskit.primitives import Sampler\n",
        "from qiskit.circuit.library import EfficientSU2\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h-xzQTWOsOT"
      },
      "outputs": [],
      "source": [
        "class VarationalQuantumClassifier:\n",
        "   def __init__(self) -> None:\n",
        "        self.data_path = \"/content/oito_sitios (1).csv\"\n",
        "        annni_dataset = pd.read_csv(self.data_path)\n",
        "        self.X = annni_dataset[['feature_5','feature_6','feature_7','feature_9','feature_10','feature_11']]\n",
        "        self.y = annni_dataset['label'] -1\n",
        "        self.y = self.y.to_numpy().reshape(-1, 1)\n",
        "        self.g = annni_dataset['g']\n",
        "        self.k = annni_dataset['k']\n",
        "\n",
        "   def process_data(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X , self.y, test_size=0.3, random_state=44)\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        return X_train, X_test, y_train, y_test  # Retorna y_train e y_test sem codificação one-hot\n",
        "\n",
        "   def model_and_score(self):\n",
        "        X_train, X_test, y_train, y_test = self.process_data()\n",
        "        feature_map = ZFeatureMap(feature_dimension=6, reps=3)\n",
        "        otimizador = SPSA(maxiter=100)\n",
        "        sampler = Sampler(options={'shots':600})\n",
        "        ansatz = EfficientSU2(6, reps=5, entanglement='linear', insert_barriers=True)\n",
        "        vqc = VQC(sampler = sampler,feature_map=feature_map ,ansatz=ansatz,optimizer = otimizador)\n",
        "        vqc.fit(X_train,y_train)\n",
        "        predictions = vqc.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "        print(accuracy)\n",
        "        return vqc\n",
        "\n",
        "   def plot_graph(self,modelo):\n",
        "        scaler = MinMaxScaler()\n",
        "        X = scaler.fit_transform(self.X)\n",
        "        predict = modelo.predict(X)\n",
        "        plt.scatter( self.g,self.k, c=predict)\n",
        "        plt.title('Model of ANNNI with VQC')\n",
        "        plt.xlabel('k')\n",
        "        plt.ylabel('g')\n",
        "        plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE87qccdjmlI"
      },
      "source": [
        "**Usando o normalize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BR0W5_KjrcL"
      },
      "outputs": [],
      "source": [
        "class VarationalQuantumClassifier:\n",
        "   def __init__(self) -> None:\n",
        "        self.data_path = \"/content/sample_balanced_oito_sitios_label.csv\"\n",
        "        annni_dataset = pd.read_csv(self.data_path)\n",
        "        self.X = annni_dataset[['feature_5','feature_6','feature_7','feature_9','feature_10','feature_11']]\n",
        "        self.y = annni_dataset['label'] -1\n",
        "        self.y = self.y.to_numpy().reshape(-1, 1)\n",
        "        self.g = annni_dataset['g']\n",
        "        self.k = annni_dataset['k']\n",
        "\n",
        "   def process_data(self):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X , self.y, test_size=0.3, random_state=44)\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train_normalized = normalize(X_train, norm='l2')\n",
        "        X_test_normalized = normalize(X_test, norm='l2')\n",
        "\n",
        "        return X_train_normalized, X_test_normalized, y_train, y_test  # Retorna y_train e y_test sem codificação one-hot\n",
        "\n",
        "   def model_and_score(self):\n",
        "        X_train, X_test, y_train, y_test = self.process_data()\n",
        "        feature_map = ZFeatureMap(feature_dimension=6, reps=3)\n",
        "        otimizador = SPSA(maxiter=100)\n",
        "        sampler = Sampler(options={'shots':600})\n",
        "        ansatz = EfficientSU2(6, reps=5, entanglement='linear', insert_barriers=True)\n",
        "        vqc = VQC(sampler = sampler,feature_map=feature_map ,ansatz=ansatz,optimizer = otimizador)\n",
        "        vqc.fit(X_train,y_train)\n",
        "        predictions = vqc.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "        print(accuracy)\n",
        "        return vqc\n",
        "\n",
        "   def plot_graph(self,modelo):\n",
        "        X = normalize(X, norm='l2')\n",
        "        predict = modelo.predict(X)\n",
        "        plt.scatter( self.g,self.k, c=predict)\n",
        "        plt.title('Model of ANNNI with VQC')\n",
        "        plt.xlabel('k')\n",
        "        plt.ylabel('g')\n",
        "        plt.grid()\n",
        "\n",
        "\n",
        "model = VarationalQuantumClassifier()\n",
        "modelo = model.model_and_score()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}